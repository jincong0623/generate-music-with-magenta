# Midinet
## 摘要
- 基于GAN的一种CNN——Midinet，旨在提供一般的、用于符号音乐的高度自适应网络结构。
- 适用于1D或2D的条件。1D：运用预计的和弦和现有的小节A；2D：之前的小节A和由A生成的小节B。
- 以随机的噪声为输入，一小节一小节地生成音符序列；每次的输出为16*128的矩阵，表示每小节的旋律的记录基础为以16分音符为节拍单位，128个MIDI音符的旋律序列。多个矩阵串联即为音乐序列的输出结果。

## 与RNN的比较
- 基于生成式对抗网络GAN
- 基于卷积神经网络CNN
- RNN可以直接生成音乐而不是MIDI数据，但RNN的训练过程较慢，且添加约束条件不够直接
- midinet用于生成主旋律序列，而不是生成不断的连续旋律序列
- 通过1D条件可以添加更多相关组成的高度自适应结构，用于复杂的、分层时态模式（跨时间）、调和关系（主旋律和伴随音）。
- 通过2D的随时间推移音符作为CNN的输入。与时间相关旋律之间的依赖可以不使用RNN中的重复单元进行建模，而在音乐中建立长期的时间依赖性。

## 方法
1. 核心：一种改进的深度卷积对抗网络（DCGAN）——学习固定时长的符号音频
2.  生成器模型
- 与进行图像相关的CNN设计时运用2D卷积过滤器进行特征学习相比，音频数据是连续的，且足够充分运用1D卷积过滤器
- 在最终转置层使用h-by-1型过滤器（h表示路由网络中MIDI音符的个数）
- 中间卷积转置层序列将由随机数组成的向量转化为近似h-by-w型的2D矩阵作为输出（对应于在当前第w个单元所出现的不同的音符），第一转置卷积层的过滤器的大小为1-w（如图所示，h为128，w为16）
3. 鉴别器模型
- 典型的CNN，有两个卷积层和两个密集层
- 用于辨别一小节真实的旋律序列和一小节人造（仿制）的旋律序列（序列为2D有代表性的，比如h-by-w矩阵）
4. 1D的条件
- 不仅是两个模型的输入层输入1D条件，也要在所有中间层输入此条件
- 一般1D条件表示为一个n维向量
- 在a-by-b型中间层加入1D条件：将调节的向量投射到相同的矩阵形状得到a-by-b-by-n的张量，并将它与特征映射轴中的中间层连接（图中的橙色块）
5. 2D条件：反射CNN
- GAN的生成结果为关于时间和频率信息的2D矩阵，对矩阵的每个部分执行调节，得到满足条件的2D矩阵
- 2D条件映射到中间层的方法：训练另一个与生成器模型的CNN相同结构的CNN（层的数量以及过滤器的数量和大小相同），但此CNN是以h-by-w的条件矩阵作为输入而1D向量作为输出的，此CNN即为反射CNN（原CNN与反射CNN的参数通常是不同的）
- 一般不对鉴别器模型使用2D条件*

## 实验的实施
1. 数据集
- 和弦符号作为1D条件以及再生成的旋律小节序列作为2D条件，即需要的数据是包含旋律以及和弦的多小节序列的MIDI数据集。试验中实际使用的是从网上收集到的1022个包含和弦和旋律信息的分轨MIDI数据集
- 为简化数据，通过过滤器摘选，只保留MIDI中24个基本三和弦中的和弦（13个基本音为根音的大小三和弦），选取8小节长度，并将和弦轨与旋律轨分离
- 旋律数据的处理：以十六分音符为最小单位，并跳过休止符（排除含有较多三连音或三十二分音符的MIDI数据），得到可以表示旋律序列的高度h为16、宽度w为128的矩阵
- 和弦数据的处理：使用13维的向量，第1维用于表示和弦类型（大三/小三），剩下的12维用于标记三和弦中的3个音（一个八度内的12个音中），12个维度是一个八度C到B按照顺序排列的，小和弦对应于主和弦的相对相对小调（如图表所示），并调整至每个小节只有一个和弦
- 经过上述预处理留下了526个MIDI数据，4208条旋律和弦数据对，使用密钥换位技术对数据进行扩充，最终得到4208*12小节的数据对来训练MidiNet

2. MidiNet的训练
- 为充分利用所有的小节数据，每次训练出两个连续的小节作为2D条件，前一个作为2D条件使用，后一个作为真正的旋律
- 假设鉴别器模型在未知之前小节的旋律情况下的能够区分真正的旋律和生产的旋律，因此对鉴别器模型使用1D条件而对生成器模型使用1D和2D条件
- 和弦的作为1D条件的作用是在两种模型中平衡前后旋律
- 由于非凸非合作博弈均衡效应，GANs训练出现不稳定和模式崩溃的问题。对优化问题和模型架构的深入分析后，最近提出一些技术解决问题，并据此训练稳定的GANs。此次试验中采用了特征匹配以及单边标签平滑技术（http://www.myzaker.com/article/584d5ca67f780b7476006685/ ）
- 在训练阶段发现，用前一小节的真实旋律作2D条件，生成器模型每次只生成一小节的旋律。在测试阶段中每次使用由先前小节生成的旋律作为2D条件，先后生成了完整的8小节旋律。

## 结果
- 图中（a）为只有1D和弦条件，（b）中运用了1D以及2D条件
- 这两种都出现了MidiNet产生的旋律音符也出现在和弦中的情况，说明1D和弦条件是有效的
- 可以看到当使用2D条件时MidiNet可以生成一些重复音符来增强相邻小节的相关联性

## 讨论和结论
- MidiNetde设计灵感：来自于人的作曲方式————首先存在一定和弦顺序的印象，然后再填补旋律线的每个小节
- 模型的不足之处：局限于旋律和弦以及相邻小节旋律的关系————需要保持其结构灵活并且容纳足够的音乐理论知识和洞察力；时长过段，需要考虑更高层次的音乐以及完整的歌曲结构
- 与RNNs相比较，RNN的顺序模式较强，但基于CNN的模型可以由2D条件提高两相邻小节旋律的关联性；从对先前小节旋律的运用，有助于将来长时顺序信息的学习
- 综合MidiNet中含有更多计算模型来处理音乐信息的不同方面，如自动和弦识别，音乐自动标记以及音乐情感识别。若计算模型可以额外提供更多有意义的反馈给生成器模型，则将更容易控制所生成音乐的类型和感觉，这可能会创造出音乐生成的新应用