## 07.21--07.27 王雪婷

### 1、本周完成的工作

翻译英文文献《generate music with RNN》（翻译文本用Word文档上传），对其中讲到的乐理知识、算法思路有了一定的了解，对不能理解的地方做了标注（有翻译同篇文章的大佬希望能给予帮助 = =*）

对《generate music with RNN》后面的文献进行了整理（已打包上传），有需要的同学可以一起看看~



### 2、收获
1）了解了RNN在音乐创作中的**发展历程**，包括：时间、人物、事件等。

2）知道了**乐理**的一些基础知识，包括：12音、音阶、小节、五度圈等。

3）大致了解了本文团队的**实验理念和过程**：首先是用π来做歌曲的原型（因为π是一个无限不循环小数，它包括了所有数字组合的集合）→→→→→其次在音阶上选择了简化，让所用的音符都从C开始变化（虽然有4中音阶，12个音，也就是48种组合，但是通过实验，他们将自己数据库中的所有歌曲都标准化了）→→→→→然后对于旋律的描述，他们运用两层RNN（一个做“键层”，控制旋律什么时候开始，一个做“按键层”，控制旋律持续的时间），这里，还运用到了LSTM来简化它们的运算，其中的“键层”是一个512维的隐藏状态的双层LSTM（具体的实施和公式在论文中）→→→→→然后研究了音乐的和弦与鼓点，他们找到和弦、鼓点与旋律之间的关系，并涉及预测它→→→→→训练程序（用交叉熵作为损失函数）（这个概念没有被细讲，我也没查到）→→→→→生成音乐。

4）**实验内容**：他们通过对100小时音乐的训练，让测试者听最后生成的音乐，并与谷歌生成的、他们自己不完善的音乐进行对比聆听，选出让人更舒服、喜欢的音乐，以此证明他们实验的成功（具体结果在论文中）。

5）**成果**：他们将自己的成果生成了两个简单的应用，分别是“神经舞蹈和唱歌”和“神经故事唱歌”（都是直译），应用结果显示：可以出大部分正确的结果，但仍有需要完善的地方。

6）**总结**：在模型设计中，提出了一种基于音乐理论的流行歌曲生成方法。与过去的工作相比，他们的方法能够产生多音轨的音乐。
### 3、不足

每次阅读文献不能连贯，前面读，后面忘，之后应该会通过做笔记之类的方式改善……